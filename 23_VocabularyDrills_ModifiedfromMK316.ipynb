{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VocabularyDrills_ModifiedfromMK316.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/Python_Basics/blob/main/23_VocabularyDrills_ModifiedfromMK316.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üêπ üêæ üç© Vocabulary Drills\n",
        "\n",
        "#üìò **Topic 03 Pronunciation teaching**\n",
        "\n",
        "**Table of Contents:**  \n",
        "using **{gTTS}** Text-to-Speech & CMU pronunciation dictionary.  \n",
        "\n",
        "* Exposure to Keyword pronunciation (using üìä_frequency distribution, gTTS_)\n",
        "* English rhyming (using üìÉ_CMU dictionary_): e.g., night, right, bite, etc.\n",
        "* Learning English vowels with rhyming words.\n"
      ],
      "metadata": {
        "id": "f1lUplgVnuvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üê£ <font color = 'brown'> **Preprocessing ** ‚§µÔ∏è\n",
        "\n",
        "**For Your Information** \n",
        "\n",
        "**[NLTK package & punkt module](https://www.askpython.com/python-modules/nltk-punkt)**\n",
        "\n",
        "**[corpus-toolkit package](https://kristopherkyle.github.io/corpus_toolkit/)**\n",
        "\n",
        "  - **pip**\n",
        "    - \"pip\" is a package-management system written in Python and is used to install and manage software packages. \n",
        "    - \"pip install\" will execute the setup.py file in the current directory.\n",
        "  \n",
        "  -[package] **corpus-toolkit** is ... \n",
        "  \n",
        "  -[package] **NLTK** (Natural Language Toolkit) is used in Python to implement programs under the domain of Natural Language Processing. It contains a variety of libraries for various purposes like text classification, parsing, stemming, tokenizing, etc.\n",
        "  -[module] In NLTK, **PUNKT** is an unsupervised trainable model, which means it can be trained on unlabeled data (Data that has not been tagged with information identifying its characteristics, properties, or categories is referred to as unlabeled data.) It generates a list of sentences from a text by developing a model for words that start sentences, prepositional phrases, and abbreviations using an unsupervised technique. Without first being put to use, it has to be trained on a sizable amount of plaintext in the intended language."
      ],
      "metadata": {
        "id": "iiJrLU8I6R2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nomalization\n",
        "###**Stemming** \n",
        "* am ‚Üí am,   having ‚Üí hav,   the going ‚Üí the go\n",
        "\n",
        "###**Lemmatization** \n",
        "* am ‚Üí be,   having ‚Üí have,  the going ‚Üí the going"
      ],
      "metadata": {
        "id": "hjbq3ODJR0BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### ‚úèÔ∏è **Student's activity\n",
        "#@markdown ### üëÄ. <font color = 'brown'> **Install and import packages**\n",
        "\n",
        "!pip install corpus-toolkit\n",
        "\n",
        "import nltk               #Python-internal package\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  #from PackageName.ModuleName import FunctionName\n",
        "nltk.download('punkt')    #additional downloading of the 'punkt' module"
      ],
      "metadata": {
        "id": "wdqxWWG8A6wd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity1** ‚§µÔ∏è\n",
        "\n",
        "!pip install corpus-toolkit\n",
        "\n",
        "import nltk               \n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  \n",
        "nltk.download('punkt') "
      ],
      "metadata": {
        "id": "7klrhXnbl26S",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üíæ Sample text: [Crime and punishment](https://raw.githubusercontent.com/ms624atyale/Data_Misc/main/Crime_Punishment_ChOne_Part.txt) Copy and get it ready to past below üë†üë† "
      ],
      "metadata": {
        "id": "RlifI_rHqEJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbN8TYs6nZjK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown #### 2.üëÄ <font color = 'brown'> **Paste your text here for analysis: (text)**\n",
        "text = input('Enter a text either by typing or doing a copy & paste:')\n",
        "\n",
        "#@markdown #### 3.üëÄ <font color = 'brown'> **Create a folder named \"txtdata\" for further processing**\n",
        "import os #os module Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "os.mkdir(\"txtdata\") #os modulÏùò mkdir()function ÏÇ¨Ïö©\n",
        "\n",
        "#@markdown #### 4.üëÄ <font color = 'brown'> **Write a text to a file under 'txtdata' folder**\n",
        "\n",
        "with open('txtdata/mytext.txt','wt') as f:\n",
        "  f.write(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity2** ‚§µÔ∏è\n",
        "\n",
        "text = input('Enter text here:')\n",
        "\n",
        "import os \n",
        "os.mkdir(\"txtdata\") \n",
        "\n",
        "with open('txtdata/mytext.txt','wt') as f:\n",
        "  f.write(text)"
      ],
      "metadata": {
        "id": "tvJKTRRGmdnD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">## üê£ **Frequency analysis:** your actions required two times ‚§µÔ∏è\n",
        "\n",
        "  - [Regular Expression](https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html)\n",
        "\n",
        "archive: #The \" \\w \" means \"any word character\" which usually means alphanumeric (letters[a-zA-Z], numbers[0-9]) plus underscore (_). "
      ],
      "metadata": {
        "id": "TRh-brZf6ZIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 5.üëÄ Tokenize using Regular expression & converting eveything to lower case\n",
        "\n",
        "#??getting frequency list with tagging information\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\") #any charcters or numbers with at least more than one character before\n",
        "words = retokenize.tokenize(text) #variable.tokenize module\n",
        "\n",
        "# Lower case\n",
        "wlist = []\n",
        "for w in words:\n",
        "  w1 = w.lower()\n",
        "  wlist.append(w1)\n",
        "\n",
        "words = wlist\n",
        "print('Word count before excluding stopwords: %d'%len(words))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R9B_7_tyk7w8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity3** ‚§µÔ∏è\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\") \n",
        "words = retokenize.tokenize(text) \n",
        "\n",
        "# Lower case\n",
        "wordlist = []\n",
        "for w in words:\n",
        "  w1 = w.lower()\n",
        "  wordlist.append(w1)\n",
        "\n",
        "words = wordlist\n",
        "print('Word count before excluding stopwords: %d'%len(words))\n",
        "\n"
      ],
      "metadata": {
        "id": "IWDcNSb1nvJo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 6.üëÄRemove stopwords \n",
        "\n",
        "# import stopwords from nltk.corpus\n",
        "\n",
        "from nltk.corpus import stopwords #Ïó¨Í∏∞ÏóêÏÑú stopwordsÎäî function\n",
        "nltk.download(\"stopwords\") #module()ÏïàÏóê ÏÇ¨Ïö©ÌïòÎäî double quotes \"\" ÏÜçÏóê function Îì§Ïñ¥Í∞ÄÎäîÏßÄ ÌôïÏù∏ ÏöîÎßù\n",
        "\n",
        "words = [w for w in words if not w in stopwords.words('english')] #Ïó¨Í∏∞ÏÑú stopwordsÎäî moduleX, variable nameX, Î≠òÍπåÏöî?\n",
        "print('Word count after excluding stopwords: %d'%len(words))\n",
        "\n"
      ],
      "metadata": {
        "id": "p-f1pa8QBVsY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity4** ‚§µÔ∏è\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download(\"stopwords\") \n",
        "\n",
        "words = [w for w in words if not w in stopwords.words('english')] \n",
        "print('Word count after excluding stopwords: %d'%len(words))\n"
      ],
      "metadata": {
        "id": "XMVip4QgoPMy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 7.üëÄPOS Tagging (abbr. Part of Speech (i.e., grammatical categories))\n",
        "\n",
        "from corpus_toolkit import corpus_tools as ct #from ExtPackageName import ModuleName\n",
        "\n",
        "brown_corp = ct.ldcorpus(\"txtdata\") #load and read text files under 'txtdata' directory\n",
        "tok_corp = ct.tokenize(brown_corp)  #tokenize corpus - by default this lemmatizes as well\n",
        "brown_freq = ct.frequency(tok_corp) #creates a frequency dictionary\n",
        "\n",
        "ct.write_corpus(\"tagged_txt\",ct.tag(ct.ldcorpus(\"txtdata\"))) #loading & reading under the txtdata folder Ìïú Í≤ÉÏóê tagging per tokenÌïòÍ≥†, Ïù¥ Í≤∞Í≥ºÎ•º tagged_txtÎùºÎäî ÌååÏùºÎ°ú Ï†ÄÏû•ÌïòÍ∏∞. \n",
        "tagged_freq = ct.frequency(ct.reload(\"tagged_txt\")) #POS tagging per tokenÏùÑ Ï†ÄÏû•Ìïú tagged_txt ÌååÏùºÏùÑ Î©îÎ™®Î¶¨Ïóê Ïû¨Ï†ÑÏÜ° ÌïòÍ≥†, Ïù¥Ïóê ÎåÄÌïú Îç∞Ïù¥ÌÑ∞Ïóê ÎπàÎèÑÏàò Í≥ÑÏÇ∞\n",
        "# ct.head(tagged_freq, hits = 10) #ÌÜ†ÌÅ∞ Î≥Ñ POS-tagged freq Í≥ÑÏÇ∞Ìïú Í≤∞Í≥ºÎ•º Ï≤òÏùå 10 Í∞úÏóê ÎåÄÌïòÏó¨ Î≥¥Ïó¨ Îã¨Îùº. \n",
        "\n",
        "#@markdown 8.üëÄ Saving the result above as a csv file with POS information\n",
        "\n",
        "import pandas as pd #import PyIntPackage \n",
        "data_dict = tagged_freq #Assign POS-tagged freq to \"data_dict\" variable \n",
        "data_items = data_dict.items() #POS-tagged freq \"data_dic\"Î•º Ìï≠Î™©Î≥ÑÎ°ú Ï†ïÎ¶¨\n",
        "data_list = list(data_items) #Ìï≠Î™©Î≥ÑÎ°ú Ï†ïÎ¶¨Îêú POS-tagged freq Îç∞Ïù¥ÌÑ∞Î•º Î¶¨Ïä§Ìä∏Î°ú Î≥ÄÌôò\n",
        "df = pd.DataFrame(data_list) #üçÑÎç∞Ïù¥ÌÑ∞ Î¶¨Ïä§Ìä∏Í∞Ä Îêú Í≤∞Í≥ºÎ•º ÌåêÎã§Ïä§ ÌéòÌÇ§ÏßÄÏùò DataFrame Ìï®ÏàòÎ•º Ï†ÅÏö©Ìï¥ Í∑∏ Í≤∞Í≥ºÎ•º \"df\" variable. \n",
        "\n",
        "df.columns=['Tagged_words','Freq'] #üçÑ \"df\"variable Ïó¥ÏùÑ Î¨∏ÏûêÏó¥ Î¶¨Ïä§Ìä∏Î°ú ÌïòÏó¨ Îëê ÏöîÏÜåÎ•º Ïì¥Îã§. \n",
        "mycol = list(df['Tagged_words']) # \"df\" variableÏóê \"Tagged_words\"Î•º Î¶¨Ïä§Ìä∏Ìôî ÌïòÏó¨ \"mycol\" variable Î°ú Ìï†Îãπ\n",
        "\n",
        "# print(df)\n",
        "\n",
        "# Word, POS into dataframe\n",
        "\n",
        "wordlist = [] #\"wordlist\" variableÏóê empty list ÎßåÎì§Ïñ¥ ÎÜìÍ≥†\n",
        "cat = [] #\"cat\" variableÏóê empty list ÎßåÎì§Ïñ¥ ÎÜìÍ≥†\n",
        "\n",
        "for w in mycol: #POS-tagged freqÎêú tokensÎ•º Ìï≠Î™©Ìôî ÌïòÍ≥†, Ïù¥Î•º Î¶¨Ïä§Ìä∏Ìôî Ìïú Í≤∞Í≥º Ï§ëÏóêÏÑú 'Tagged_words'Î•º Î¶¨Ïä§Ìä∏Ìôî Ìïú \"mycol\" variableÏóêÏÑú Îã®Ïñ¥Î•º ÌïòÎÇòÏî© ÎÅÑÏßëÏñ¥ ÎÇ∏Îã§.\n",
        "  w1 = w.split(\"_\") #ÎÅÑÏßëÏñ¥ ÎÇ∏ Îã®Ïñ¥Î•º '_'Í∏∞Ìò∏Î•º ÏÇ¨Ïö©ÌïòÏó¨ Î∂ÑÎ¶¨ÌïòÍ≥† Ïù¥Î•º 'w1' variableÏóê Ìï†Îãπ\n",
        "  wordlist.append(w1[0]) #\"wordlist\" variableÏóê '_'Í∏∞Ìò∏Î°ú Î∂ÑÎ¶¨Îêú Îã®Ïñ¥Ïùò Ï≤´Î≤àÏß∏ ÏöîÏÜåÎ•º Ï∂îÍ∞ÄÌïúÎã§\n",
        "  cat.append(w1[1]) #ÏúÑÏóê ÏÉùÏÑ±Ìï¥ ÎÜìÏùÄ empty cat listÏóê '_'Í∏∞Ìò∏Î•º ÏÇ¨Ïö©Ìï¥ Î∂ÑÎ¶¨Ìïú Îã®Ïñ¥Ïùò Ï≤´ Î≤àÏß∏ ÏöîÏÜåÎ•º Ï∂îÍ∞ÄÌïúÎã§.\n",
        "\n",
        "df['Word'] = wordlist #üçÑ???\n",
        "df['POS'] = cat #üçÑ???\n",
        "\n",
        "#@markdown 9.üëÄ üö© Sorting by? Answer [pop up box]\n",
        "\n",
        "print(\"Sorting by Frequency (type '1'), POS & Freq (type '2'), or by Word alphabetically (type '3')\")\n",
        "\n",
        "sorting = input()\n",
        "\n",
        "for t in sorting:\n",
        "  if t == \"1\":\n",
        "    df = df.sort_values(by=['Freq'], ascending = False)\n",
        "  if t == \"2\":\n",
        "    df = df.sort_values(by=['POS', 'Freq'], ascending = False)\n",
        "  if t == \"3\":\n",
        "    df = df.sort_values(by=['Word'], ascending = True)\n",
        "  else:\n",
        "    print(\"Type 1, 2, or 3\")\n",
        "df['Index'] = range(1,len(df['POS'])+1)\n",
        "\n",
        "df = df[[\"Index\", \"POS\", \"Word\",\"Freq\"]]\n",
        "# print df.to_string(index=False)\n",
        "\n",
        "#@markdown 10.üëÄ üö© Saving file? Answer [pop up box]\n",
        "\n",
        "print('Save it as a file? (y/n)')\n",
        "saving = input()\n",
        "\n",
        "for s in saving:\n",
        "  if s == \"y\":\n",
        "    with open('pos_wordlist.csv','w') as f:\n",
        "      df.to_csv(f)\n",
        "    print('File is saved: pos_wordlist.csv')\n",
        "  if s == \"n\":\n",
        "    print('No file will be saved.')\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "KAeAXX8RB2kn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity5** ‚§µÔ∏è\n",
        "\n",
        "from corpus_toolkit import corpus_tools as ct #from ExtPackageName import ModuleName\n",
        "\n",
        "brown_corp = ct.ldcorpus(\"txtdata\") #load and read text files under 'txtdata' directory\n",
        "tok_corp = ct.tokenize(brown_corp)  #tokenize corpus - by default this lemmatizes as well\n",
        "brown_freq = ct.frequency(tok_corp) #creates a frequency dictionary\n",
        "\n",
        "ct.write_corpus(\"tagged_txt\",ct.tag(ct.ldcorpus(\"txtdata\"))) #as of May 10, 2023\n",
        "\n",
        "tagged_freq = ct.frequency(ct.reload(\"tagged_txt\"))\n",
        "# ct.head(tagged_freq, hits = 10)\n",
        "\n",
        "#@markdown üî¥ Result saving as a csv file with POS information\n",
        "\n",
        "import pandas as pd\n",
        "data_dict = tagged_freq\n",
        "data_items = data_dict. items()\n",
        "data_list = list(data_items)\n",
        "df = pd.DataFrame(data_list)\n",
        "\n",
        "df.columns=['Tagged_words','Freq']\n",
        "\n",
        "mycol = list(df['Tagged_words'])\n",
        "\n",
        "# print(df)\n",
        "\n",
        "# Word, POS into dataframe\n",
        "\n",
        "wlist = []\n",
        "cat = []\n",
        "\n",
        "for w in mycol:\n",
        "  w1 = w.split(\"_\")\n",
        "  wlist.append(w1[0])\n",
        "  cat.append(w1[1])\n",
        "\n",
        "df['Word'] = wlist\n",
        "df['POS'] = cat\n",
        "\n",
        "#@markdown üîµ  ‚ñ∂Ô∏è   Sorting by? Answer [pop up box]\n",
        "\n",
        "print(\"Sorting by Frequency (type '1'), POS & Freq (type '2'), or by Word alphabetically (type '3')\")\n",
        "sorting = input()\n",
        "\n",
        "for t in sorting:\n",
        "  if t == \"1\":\n",
        "    df = df.sort_values(by=['Freq'], ascending = False)\n",
        "  if t == \"2\":\n",
        "    df = df.sort_values(by=['POS', 'Freq'], ascending = False)\n",
        "  if t == \"3\":\n",
        "    df = df.sort_values(by=['Word'], ascending = True)\n",
        "  else:\n",
        "    print(\"Type 1, 2, or 3\")\n",
        "df['Index'] = range(1,len(df['POS'])+1)\n",
        "\n",
        "df = df[[\"Index\", \"POS\", \"Word\",\"Freq\"]]\n",
        "# print df.to_string(index=False)\n",
        "\n",
        "#@markdown üîµ  ‚ñ∂Ô∏è   Saving file? Answer [pop up box]\n",
        "\n",
        "print('Save it as a file? (y/n)')\n",
        "saving = input()\n",
        "\n",
        "for s in saving:\n",
        "  if s == \"y\":\n",
        "    with open('pos_wordlist.csv','w') as f:\n",
        "      df.to_csv(f)\n",
        "    print('File is saved: pos_wordlist.csv')\n",
        "  if s == \"n\":\n",
        "    print('No file will be saved.')\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Bik4lR86paYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 1] Generating audio file from text (e.g., Part of Chapter 1 from Crime and Punishment by Fyodor Dostoevsky)**  \n",
        "Result file => df"
      ],
      "metadata": {
        "id": "kY-DTsXB54UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### ‚úèÔ∏è **Student's activity 6** ‚§µÔ∏è\n",
        "#@markdown üéØ üêæ**Install and import gTTS** \n",
        "%%capture\n",
        "!pip install gTTS\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "JyvQPaYiACjM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 7** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ**Word reading by gTTS**\n",
        "\n",
        "#@markdown üö© **Select word POS:** \n",
        "\n",
        "word_POS_select = \"NOUN\" #@param = [\"NOUN\",\"VERB\",\"ADJ\",\"ADV\",\"PROPN\",\"ALL\"]\n",
        "\n",
        "wordlist = df[df['POS'] == word_POS_select]\n",
        "wordlist = wordlist.sort_values(by=['Word'], ascending = True)\n",
        "\n",
        "collist = list(wordlist['Word'])\n",
        "\n",
        "print(collist)\n",
        "\n",
        "#@markdown üö© **Language to choose: (english, korean, french, spanish)**\n",
        "def tts(mytext):\n",
        "  text_to_say = mytext\n",
        "\n",
        "# Step ‚ìµ Language to choose:\n",
        "  language_to_choose = \"en\" #@param [\"en\", \"ko\", \"fr\", 'es']\n",
        "  # lang = language_to_choose\n",
        "  language = language_to_choose\n",
        "  print(\"Play language accent: %s\"%language_to_choose)\n",
        "\n",
        "  gtts_object = gTTS(text = text_to_say,\n",
        "                     lang = language,\n",
        "                    slow = False) \n",
        "  \n",
        "  gtts_object.save(\"mytext.wav\")\n",
        "  return Audio(\"mytext.wav\")\n",
        "\n",
        "# join wordlist by adding '!': joining with '.' tend to yield an error of saying two words as one. \n",
        "text_to_say = '! '.join(collist)\n",
        "intro_text = \"Okay. I'm going to read a wordlist, so repeat after me.\"\n",
        "text_to_say = intro_text + text_to_say\n",
        "tts(text_to_say)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F-DZTfmtmisZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 2] Rhyming words**\n",
        "\n",
        "**_Note:_** In the following, you'll get rhyming words from CMU dictionary.  \n",
        "* [CMU pronounciation dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)\n",
        "\n",
        "* [CMU tools](http://www.speech.cs.cmu.edu/tools/lextool.html)\n"
      ],
      "metadata": {
        "id": "T1Opo8LhEqqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üòä Let's first set up target words for today."
      ],
      "metadata": {
        "id": "pFYEIwVxFurd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 1** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ**Step 1:** Install pronouncing package\n",
        "%%capture\n",
        "!pip install pronouncing\n",
        "!pip install cmudict\n",
        "\n",
        "import pronouncing\n",
        "import cmudict"
      ],
      "metadata": {
        "id": "5K7TgrhJHN5f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\[Description]: \n",
        "\n",
        "* For a target word (your choice), we'll find rhyming words with same number of syllables. _e.g., 'grow' (1 syllable) => The result will show one-syllabled word list (randomly chosen from cmu dictionary)_\n",
        "\n",
        "* We'll then create an audio file reading the rhyming wordlist."
      ],
      "metadata": {
        "id": "eybYyZyAkRu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 2** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ**Step 2:** \tüö© Find rhyming words with <font color = 'red'> monosyllabic word: \n",
        "\n",
        "#@markdown <font color = 'blue'> Note that I find some errors (10% of error rate in pronouncing words.)\n",
        "\n",
        "print(\"Write a monosyllabic word:\")\n",
        "rhyme_with = input()\n",
        "word = rhyme_with\n",
        "\n",
        "phones = pronouncing.phones_for_word(word)\n",
        "syll_count = pronouncing.syllable_count(phones[0])\n",
        "\n",
        "print(\"Rhyming words with %s in process.\"%word)\n",
        "\n",
        "result = pronouncing.rhymes(word)\n",
        "\n",
        "print('How many rhyming words to search? (1~20')\n",
        "n_words = input()\n",
        "n_words = int(n_words)\n",
        "\n",
        "# Among the result, select words with same syllable count\n",
        "\n",
        "wlist = []\n",
        "throw = []\n",
        "\n",
        "def syllcount(x):\n",
        "  phones = pronouncing.phones_for_word(x)\n",
        "  n = pronouncing.syllable_count(phones[0])\n",
        "  return n\n",
        "\n",
        "for w in result:\n",
        "  if syllcount(w) == syll_count:\n",
        "    wlist.append(w)\n",
        "  else:\n",
        "    throw.append(w)\n",
        "\n",
        "# random sample\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "b = random.sample(wlist, n_words)\n",
        "\n",
        "temp = b[:n_words]\n",
        "\n",
        "wlist = '. '.join(temp)\n",
        "intro = \"These words rhyme with \" + str(rhyme_with) + \". \" + \"Listen carefully!\"\n",
        "\n",
        "wlist = intro + wlist\n",
        "print(\"Rhyming words: %s\"%wlist)\n",
        "\n",
        "#@markdown tts() function should be defined above [1]:\n",
        "tts(wlist)\n"
      ],
      "metadata": {
        "id": "Jc46xItsjYPp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Obg1HYCQ_wU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 3] English vowels to learn**\n",
        "\n",
        "- /i/ vs. /I/ (high front tense-lax vowel contrast)\n",
        "- /u/ vs. /U/ (high back tense-lax vowel contrast)"
      ],
      "metadata": {
        "id": "feOryD9w0B_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 1** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ**Target words to learn pronunciation:**\n",
        "\n",
        "vowel_in_word = \"i_piece\" #@param [\"i_piece\", \"I_skin\", \"u_root\", \"U_good\"]\n",
        "\n",
        "ivowel = [\"piece\", \"need\",\"meet\", \"seat\",\"see\",\"bean\",\"mean\",\"lead\",\"believe\",\"meal\"]\n",
        "iv = \".  \".join(ivowel)\n",
        "uvowel = [\"root\",\"mood\",\"who\",\"rule\",\"afternoon\",\"food\",\"suit\",\"balloon\",\"cool\",\"moon\"]\n",
        "uv = \".  \".join(uvowel)\n",
        "Ivowel = [\"skin\",\"fit\",\"bit\",\"hit\",\"sit\",\"little\",\"silk\",\"milk\",\"hill\",\"ill\"]\n",
        "Iv = \".  \".join(Ivowel)\n",
        "Uvowel = [\"good\",\"book\",\"cook\",\"would\",\"could\",\"should\",\"wood\",\"wolf\",\"woman\",\"put\"]\n",
        "Uv = \".  \".join(Uvowel)\n",
        "vlist = {'i_piece': iv, 'I_skin': Iv, 'u_root': uv, 'U_good': Uv}\n",
        "\n",
        "text_to_say1 = vlist.get(vowel_in_word)\n",
        "intro = \"I'll be saying ten words that share the same vowel. Listen carefully. \"\n",
        "\n",
        "text_to_say = intro + text_to_say1\n",
        "print(vlist[vowel_in_word])\n",
        "tts(text_to_say)\n"
      ],
      "metadata": {
        "id": "6gakCNG59PiW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 2** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ **Minimal pair**\n",
        "twowords = input()\n",
        "tts(twowords)"
      ],
      "metadata": {
        "id": "lBaeuprZF-OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 4] Larning English vowels with rhyming words**\n",
        "### **3.1 9 Monophthongs (simple vowels) and 5 diphthong vowels in English**\n",
        "\n",
        "* Note: Vowel inventories may differ from one dialect to another. We follow abstractly defined General American English vowel system. (See Ladefoged & Johnson (2017), A course in Phonetics."
      ],
      "metadata": {
        "id": "Os9nUHeEOK7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### English monophthong vowels: 10 vowels (**The schwa vowel** is excluded here)\n",
        "\n",
        "![](https://github.com/MK316/workshop22/raw/main/img/englishvowels1.png)"
      ],
      "metadata": {
        "id": "R2PZKG9blvIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 1** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ**Install pronouncing, gTTS, IPython packages**\n",
        "%%capture\n",
        "!pip install pronouncing\n",
        "!pip install gTTS\n",
        "\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "import pronouncing"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xGu6WpNxmlIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 2** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ **Step2:** üö© Vowels to learn:\n",
        "\n",
        "#@markdown üê≥ Note: 'taught' has the same vowel with 'top' in the speaker's dialect.\n",
        "Target_vowel_as_in = \"taught\" #@param [\"bean\",\"bin\",\"Ben\",\"ban\",\"mood\",\"would\",\"taught\",\"nod\", \"mud\",\"go\",\"how\",\"bay\",\"bye\",\"boy\"]\n",
        "\n",
        "word = Target_vowel_as_in\n",
        "\n",
        "#@markdown üê≥ Number of syllable: 1~3 (Select \"ignore\" for not using this option.)\n",
        "number_of_syllables = \"1\" #@param [\"1\",\"2\",\"3\",\"4\",\"ignore\"]\n",
        "\n",
        "# phones = pronouncing.phones_for_word(word)\n",
        "# syll_count = pronouncing.syllable_count(phones[0])\n",
        "\n",
        "result = pronouncing.rhymes(word)\n",
        "\n",
        "# syllable number counting as function\n",
        "def syllcount(x):\n",
        "  phones = pronouncing.phones_for_word(x)\n",
        "  n = pronouncing.syllable_count(phones[0])\n",
        "  return n\n",
        "\n",
        "wlist = []\n",
        "\n",
        "# (syllcount(w) == 1 or 2)\n",
        "for w in result:\n",
        "  if (number_of_syllables == \"ignore\"):\n",
        "    wlist.append(w)\n",
        "  elif (int(number_of_syllables) == syllcount(w)) and (len(w) > 1):\n",
        "    wlist.append(w)\n",
        "  else:\n",
        "    throw.append(w)\n",
        "\n",
        "print(\"Rhyming words: %d\"%len(wlist))\n",
        "\n",
        "How_many_words_to_show = \"10\" #@param = [\"5\",\"10\",\"15\",\"20\",\"30\"]\n",
        "n_words = int(How_many_words_to_show)\n",
        "# random sample\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "if len(wlist) > n_words:\n",
        "  b = random.sample(wlist, n_words)\n",
        "  temp = b[:n_words]\n",
        "else:\n",
        "  temp = wlist\n",
        "\n",
        "\n",
        "# wordlist as dataframe to display\n",
        "import pandas as pd\n",
        "dft = pd.DataFrame()\n",
        "dft['Words'] = temp\n",
        "\n",
        "wlist = '. '.join(temp)\n",
        "intro = \"These are randomly chosen \" + str(n_words) + \" words that rhyme with \" + str(word) + \". \" + \"Listen carefully! \"\n",
        "\n",
        "wlist = intro + wlist\n",
        "print(\"Rhyming words: \\n %s\"%wlist)\n",
        "print(\"*** Target vowel in '%s'\"%word)\n",
        "print(dft)\n",
        "\n",
        "tts(wlist)\n"
      ],
      "metadata": {
        "id": "SemVkl3rpSnv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 3** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ**More words rhyming with the word you've chosen in Student activity 2 above.\n",
        "print(result)"
      ],
      "metadata": {
        "id": "1shwPwf85e4W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # ‚úèÔ∏è **Student's activity 4** ‚§µÔ∏è\n",
        "\n",
        "#@markdown üéØ üêæ** üê≥ Type in a word and find its stress pattern: \n",
        "wordstress = input()\n",
        "pronouncing.stresses(pronouncing.phones_for_word(wordstress)[0])"
      ],
      "metadata": {
        "id": "OmvSWUTFQSMQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**You did a good job!** üç∏üç∑ üçª üçï üçî üçü "
      ],
      "metadata": {
        "id": "T2bslJROG1WZ"
      }
    }
  ]
}